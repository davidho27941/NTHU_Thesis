\chapter{Data analysis and Event reconstruction}\label{section:Reconstruction}

In this chapter, we will explain the event selection and the different appraoch for jet-parton assignment problem. Before event reconstruction, an event selection is required. An event selection can help us by removing the events that is not a target of our analyze from the dataset. For a supervised ML training, a groud truth (correct answer) is indeed. To generate the answer (i.e. correct assignment of jet), we compute the distance between parton and jet. A jet that produce by the detector simulation would be assigned to a parton when it close enough to a parton. 
\\
In the traditional method, such as $\chi^{2}$ method or \textbf{Kinematic Likehood Fitter (KLFitter)}, need to compute all the possible combinations. This usually need a large computational power, but cannot guaranties high reconstruction efficiency due to the prior constraint. A well-trained ML model can help us to find a ``function'' that solves the problems without large computation time. In this project, we designed a ML network based on the attention mechanism and the permutation symmetry of final state particles. This ML network will be examined by the traditional method. The reconstruct efficiency, computation time, and invariant mass are the item to be compared. 
\\
\section{Data analysis}\label{sec:Data analysis}

\subsection{Event selection}\label{subsec:Event selection}
The all hadronic top-quark decay channel has two b-jets and four quark jets. In our configuration, all of them are not in the boosted region, which means the daughters of top quarks will not appear with high transverse momentum. Following the event selection used in \cite{Mccarthy:2015ucy},  we apply an event selection that an event should at least exists \textbf{two b-jets} and \textbf{four quark jets} satisfied $p_{\rm T}$ larger than \textbf{25 GeV} and $|\eta|$ less than \textbf{2.5}. A set of cuts with kinematics limitation may helps to see the evolution of surviving event numbers. The rule of cuts is shown in Table \ref{table:cuts}, and the cutflow is shown in Figure \ref{fig:cutflow}.
\\
\begin{center}
	\begin{table}[h]
		\begin{tabular}{p{0.1\textwidth} c c c }
			\cline{1-3}
			\#Cut    & Number of b-jets & Number of quark jets  \\
			\hline
			C1      &   0  & 4    \\
			C2      &   0  & 5    \\
			C3      &   0  & 6    \\
			C4      &   1  & 6    \\
			C5      &   2  & 6    \\
			\hline
		\end{tabular}
		\caption{Rule of cuts. All the cuts require a kinematic limitation that $p_{T} > 25$ GeV and $|\eta|<2.5$.}
		\label{table:cuts}
	\end{table}
\end{center}
The b-tagging and jet information we used here is provided by the Delphes, a detector simulation package\cite{deFavereau:2013fsa}. The b-tagging is a method of jet flavor tagging used in CMS and ATLAS\cite{ATLAS:2016gsw}\cite{Sirunyan:2017ezt}. This method base on the b-hadron properties, such as the displaced vertex from the primary vertex, large b-hadron mass, large impact parameters (d0), and semi-leptonic e/$\mu$ decay of B-hadron. This is also related to the track reconstruction and secondary vertex reconstruction. The Delphes package decide a jet is b-tagged or not based on an efficiency table and returns an array to indicate a jet is b-tagged or not.
\\
The number of surviving events is an important factor in our event generation. If the surviving events are very rare, it would mean that our cuts are too tight and the events desired may also possibly be ignored. Also, the lack of surviving events may slow down our data generation efficiency. In Figure \ref{fig:cutflow}, it shows that there are around 18 $\sim$ 20\% events that surviving after C5 cut. This is an acceptable number because we obtain that the events in our dataset will at least contain two b-tag jets and six jets that passed the kinematics selection without ignoring too many events.
\\
\begin{figure}[H]
	\includegraphics[width=0.9\linewidth]{Figures/ttbar_cutflow.png}
	\caption{Cutflow of all hadronic top decay. About hald of the events will be killed by the requirement of six quark jets. Only ~20\% events survived after including two b-jets requirement.}
	\label{fig:cutflow}
\end{figure}
\subsection{Truth matching}\label{subsec:Truth matching}
The \textbf{truth matching}, which is also called \textbf{$\Delta$R matching},  matches the detector simulation(i.e. jet information generated by Delphes) data to truth record(i.e. Parton level information).  To calculate the $\Delta R$ value, we will find the daughters of top quarks, W boson, and b quark. Once the daughters of top quarks are found, we can find the daughters of W bosons. Finally, we obtain six partons that come from the decay of top quark pairs. These six partons can match the jets identically by considering their distances. The formula of calculating $\Delta R$ is:
\\
\begin{equation}
	\Delta R = \sqrt{\Delta\eta^{2} + \Delta\phi^{2}}.
\end{equation}
By using the kinematic properties provided in parton level and detector simulation information, we can calculate the $\Delta R$ value between each parton and jets. Using the result of the calculation, we may assign each parton to a specific jet. 
\\
\newpage
\subsection{Custom barcode system}\label{subsec:barcode}
To specify the relation between each parton, and the relation between mothers and daughters, we design a barcode system that helps us to declare the relationship.
\begin{figure}[H]
	\centering
	\includegraphics[width=1.1\linewidth]{Figures/barcode.pdf}
	\caption{Barcode design. These barcodes can provide a pari-wide information to our network.}
	\label{fig:barcode}
\end{figure}
In Figure \ref{fig:barcode}, we define a six-digit barcode, the first two digits are to show which top quark is the mother of this parton and the last four digits of the sequence declare which daughter of the top quark is the mother of parton. Our barcode system breaks six parton (jet) candidates into two subsets which contain three elements. Our barcode system is able to specify the relation without losing the information, and also provide a permutation relationship to our network. This will discussed this in the following section.
\\
\newpage
\section{Event reconstruction}\label{sec:Event reconstruction}
\subsection{$\chi^{2}$ minimization method}\label{subsec:chi-square}
The $\chi^{2}$ minimization method is a traditional method to reconstruct an event. An event that exists 6 jets, it has about $6!/(2\times2\times2)=90$ possible combinations, the first two in the denominator is contributed by two b-tag jets, and the middle one and last one is the contributions from two pairs of quark produce by W bosons. The number of possible combinations is proportional to the number of existing jets in an event. The $\chi^{2}$ minimization method can calculate all the candidates and will try to find the candidate which has the smallest $\chi^{2}$ value. This method based on the mass of the W boson and top quark. The origin equation of $\chi^{2}$ minimization in this model is:
\begin{equation}\label{eqn:chi2}
	\chi^{2} = \frac{( m_{bqq'} - m_{t} )^{2}}{\sigma_{\rm t}^{2}} + \frac{( m_{\bar{b}q''q'''} - m_{t} )^{2}}{\sigma_{\rm t}^{2}} + \frac{(m_{qq'} - m_{\rm W})^{2}}{\sigma^{2}_{\rm W}} + \frac{(m _{q''q'''} - m_{\rm W})^{2}}{\sigma^{2}_{\rm W}}.
\end{equation} 
The equation (\ref{eqn:chi2}) has four part. Each parts is a ``pull'' that is contributed by the component of observables. The parameter $\sigma_{\rm W}$ and $\sigma_{\rm t}$ is obtained by applying a fitting to the distribution of reconstructed invariant mass of W boson and top quarks. The mass of the W boson and top quark is provided by the recent experiment result. To avoid the bias of top quark candidates, we may combine the first two term into one term by substituting $m_{\rm t}=\frac{m_{bqq'} + m_{\bar{b}q''q'''}}{2}$, then the equation reduces to: 
\begin{equation}\label{eqn:chi2_mod}
	\chi^{2} = \frac{(m_{bqq'} - m_{\bar{b}q''q'''})^{2}}{\sigma^{2}_{\Delta_{\rm m_{bqq'}}}}  + \frac{(m_{qq'} - m_{\rm W})^{2}}{\sigma^{2}_{\rm W}} + \frac{(m _{q''q'''} - m_{\rm W})^{2}}{\sigma^{2}_{\rm W}}.
\end{equation} 
Note that there are some events in which the three-jets invariant mass can be far away from the top quark mass but still generate a small $\chi^{2}$ value. This is because we only consider the difference between two three-jets invariant mass. This can be improved by applying a constraint to the invariant mass\cite{Mccarthy:2015ucy}, but we didn't apply such a constraint in this study. 
\\
In this project, we force the b quark candidates in equation \ref{eqn:chi2_mod} must be b-tagged jets. This may help to reduce the number of permutations. This restriction may also lead to a incorrect assignment since a jet can be tagged incorrectly.
\subsection{Machine Learning Approach}\label{subsec:ML approach}
For a machine learning model, equivariance and invariance are important properties that may affect the performance of the model. Such as a computer vision problem, the object should be invariant under translation to prevent affect the prediction. The translation, rotation, and shift of the position should not change the prediction of the model because the object remains the same object. The Convolutional Neural Network (CNN) can produce object recognition outcomes that are invariant under translations. The properties of invariance can be generalized to another geometry structure, e.g. manifolds and groups. In all hadronic top decay, we have two subsets with the same elements $(b, q, q')$ and $(\bar{b}, q'', q''')$. These subsets should remain invariant under permutations of the input jets order. The reason that the order of input jets should not affect the result is because the permutation symmetry is not base on the order of jets but the pair-wise permutation.
\\
By the invariant feature of attention architecture, rearranging the elements in a sequence leaves the attention weight unchanged. This permutation symmetry present in the attention-based model may be used to render the efficient reconstruction of the all hadronic top decay process. In this case, the network output of the all hadronic top decay process should identify two distinct interchangeable subsets, and each contains an interchangeable $qq'$ pair produced by the W bosons. This invariant property on the output is the unique feature of our dataset and the model should take into account. 
\\
We propose an attention-based network, called \textbf{Symmetry Preserving Attention NETwork (SPA-NET)} in this project. Its structure is shown in Figure \ref{fig:architecture}}. The input of SPA-NET is a list of unsorted jet information, with their 4-momentum $(p_{\rm T}, \eta, \phi, M)$ as well as the b-tag information provided by Delphes. We take the logarithm to $M$ and $p_{\rm T}$ and normalize all the components to have zero mean and unit variance.  The input jets will be sent to the network and be embedded into a D-dimensional latent space representation. This D-dimensional latent space is obtained by progressively increasing the latent dimensionality of the input jets up to the final dimensionality D (This operation is done by the embedding blocks in the whole stack). We target this latent space dimensionality D to a value 128 with the following sequence: 8 $\to$ 16 $\to$ 32 $\to$ 64 $\to$128.  After embedding, the output will be sent to a stack of transformer encoder layers, this layer will learn the relationship between each element in the input sequence. When the encoding is finished, the encoded output will be forwarded into an important architecture in this network - a two-branched structure with each branch  able to compute the output individually. Each branch has a transformer encoder layer whichl extract the information from the top quark and a tensor attention layer which produce the top quark distribution. The output distribution predicts the top quark triplets. Figure \ref{fig:output} is an example of network outputs; note that the attention mechanism is an architecture that allows the network to propagate the information selectively by using a  ``mask''. This enable the neural network to learn from partial information and update the parameters with selected information. Using the ``mask'' also allow the network to infer the relationships between different elements in a sequence.
\\
\begin{figure}[H]
	%\captionsetup{justification=raggedright,singlelinecheck=false}
	\centering
	\includegraphics[width=0.48\textwidth,angle=270]{Figures/NetworkDiagramAlt.pdf}
	\caption{ High-level structure of SPA-NET.}
	\label{fig:architecture}
\end{figure}
\begin{figure}[H]
	%\captionsetup{justification=raggedright,singlelinecheck=false}
	\centering
	\includegraphics[width=0.8\textwidth]{Figures/typical_output.pdf}
	\caption{A visualization of the example single event output produced by SPA-NET. The top two plots are the projected b quark distribution, and the bottom two plots are the qqâ€² distribution respectively. }
	\label{fig:output}
\end{figure}
The most important part in this network is the \textbf{Symmetry Preserving Tensor Attention}. Consider a set of weights $\theta \in \mathbb{R}^{D\times D\times D}$, this $\theta$ is not inherently symmetric at all. To make the $\theta$ become an invariant attention weighting, we apply the following transformation (equation (\ref{eqn:SPTA})). This transformation will transform the $\theta$ into an auxiliary weights tensor $S^{ijk}\in R^{D\times D\times D}$. Using $S^{ijk}$ and the embedded jets tensor $X \in \mathbb{R}^{N\times D}$ (N is the number of jets), we can calculate the dot-product attention. The dot-product works in flat Euclidean space and produces the output tensor $O^{ijk}$. The summation product tensor $S^{ijk}$ guarantees that the interchange of the first two dimensions of $S$ will be symmetric and ensures that $O^{ijk}=O^{jik}$. These properties enforce the $qq'$ invariance.
\\
\begin{equation}\label{eqn:SPTA}
	\begin{split}
	S^{ijk} &= \frac{1}{2}\left( \theta^{ijk} + \theta^{jik}\right). \\
	O^{ijk} &= X^{i}_{n}X^{j}_{m}X^{k}_{l}S^{nml}.
		\end{split}
\end{equation}
\\
To obtain the probability distributions $P^{L}$ and $P^{R}$, a 3-dimensional softmax is applied on $O^{ijk}$ to generate the joint triplet probability distribution.
\\
\begin{equation}\label{eqn:PDF}
	P(i,j,k) = \frac{exp\ O^{ijk}}{\sum_{ijk} exp\ O^{ijk}}.
\end{equation}
\\
Equation (\ref{eqn:PDF}) is used to produce the individual probability distribution of two top quarks and to produce the single triplet from each by selecting the peak of these distributions. 
\\
During the training, a suitable loss function is needed to deal with the double output probability distributions. We design the loss function based on the cross-entropy between the output probability and truth distribution on the all hadronic top decay. The loss function must ensure the symmetry of the top quark pairs which are invariant concerning the permutation $tt' \leftrightarrow t't$.  A symmetry loss function $\mathcal{L}$ by the following function:
\\
\begin{align}
		&\mathcal{L} = min(\mathcal{L}_{1}(P^{L}, T_{1}, P^{R}, T_{2}), \mathcal{L}_{1}(P^{L}, T_{2}, P^{R}, T_{1})). \\
		&\mathcal{L}_{1}(P_{1}, T_{1}, P_{2}, L_{2}) = \mathcal{H}(T_{1}, P_{1}) +\mathcal{H}(T_{2}, P_{2}).
\end{align}
\\
Where $\mathcal{H}$ is the general cross-entropy. It is possible that both branches produce the same output pairs. To make sure the network produces unique predictions, the one with the higher probability is selected and the other one is re-evaluated;the loss function is then computed. Figure \ref{fig:output} is an example of the output produced by SPA-NET.










